{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keract\n!pip install tensorflow\n!pip install pydot\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install seaborn\n!pip install scikit-image\n\nimport os\nfrom glob import glob\nimport pandas as pd\nimport numpy as np\nfrom numpy import expand_dims\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sn\nfrom skimage.transform import resize\nfrom skimage.color import gray2rgb\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom IPython.display import SVG\nimport keract\nfrom tensorflow import keras\nfrom tensorflow.keras import applications, optimizers\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.utils import to_categorical, model_to_dot, plot_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Dataset and Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/medical-image-data\"\ntrain_data_dir = \"/kaggle/input/medical-image-data/train\"\nval_data_dir = \"/kaggle/input/medical-image-data/validation\"\ntest_data_dir = \"/kaggle/input/medical-image-data/test\"\nimg_width, img_height = 150, 150 \nchannels = 3\nbatch_size = 32\ntrain_data_dir","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnv_images = len(glob(train_data_dir + '/CNV/*.jpeg'))\ndme_images = len(glob(train_data_dir + '/DME/*.jpeg'))\ndrusen_images = len(glob(train_data_dir + '/DRUSEN/*.jpeg'))\nnormal_images = len(glob(train_data_dir + '/NORMAL/*.jpeg'))\ndata= {'CNV': cnv_images, 'DME': dme_images, 'DRUSEN': drusen_images, 'NORMAL': normal_images}\nlabels = list(data.keys()) \ncount = list(data.values()) \n\nplt.rcParams['figure.figsize'] = (8.0, 8.0)\nplt.bar(labels, count, color=['tab:red', 'tab:green', 'tab:blue', 'tab:orange'])\nplt.axis('on')\nplt.xlabel(\"Labels\") \nplt.ylabel(\"Count\") \nplt.savefig('labels_vs_counts.png', transparent= False, bbox_inches= 'tight', dpi= 400)\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Histogram (Tonal Distribution)\n* Histogram of a normal retina image in the train dataset:","metadata":{}},{"cell_type":"code","source":"\nimage = mpimg.imread(data_dir + '/train/NORMAL/NORMAL-9863816-1.jpeg')\ncolor_img= gray2rgb(resize(image, (128, 128)))\nplt.rcParams['figure.figsize'] = (8.0, 5.0)\n_ = plt.hist(color_img.ravel(), bins = 256, color = 'orange', )\n_ = plt.hist(color_img[:, :, 0].ravel(), bins = 256, color = 'red', alpha = 0.5)\n_ = plt.hist(color_img[:, :, 1].ravel(), bins = 256, color = 'Green', alpha = 0.5)\n_ = plt.hist(color_img[:, :, 2].ravel(), bins = 256, color = 'Blue', alpha = 0.5)\n_ = plt.xlabel('Intensity Value')\n_ = plt.ylabel('Count')\n_ = plt.legend(['Total', 'Red_Channel', 'Green_Channel', 'Blue_Channel'])\nplt.savefig('histogram.png', transparent= False, bbox_inches= 'tight', dpi= 400)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sample Images from the Dataset","metadata":{}},{"cell_type":"code","source":"print(\"Normal\")\nmultipleImages = glob(data_dir + '/train/NORMAL/**')\ni = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor im in multipleImages[:25]:\n    image = mpimg.imread(im)\n    image_resized = resize(image, (128, 128)) \n    plt.subplot(5, 5, i+1) #.set_title(l)\n    plt.imshow(gray2rgb(image_resized)); plt.axis('off')\n    i += 1\nplt.savefig('normal_eye.png', transparent= False, bbox_inches= 'tight', dpi= 400)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Choroidal Neo-Vascularization (CNV)\")\nmultipleImages = glob(data_dir + '/train/CNV/**')\ni = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor im in multipleImages[:25]:\n    image = mpimg.imread(im)\n    image_resized = resize(image, (128, 128)) \n    plt.subplot(5, 5, i+1) #.set_title(l)\n    plt.imshow(gray2rgb(image_resized)); plt.axis('off')\n    i += 1\nplt.savefig('cnv_eye.png', transparent= False, bbox_inches= 'tight', dpi= 400)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Diabetic Macular Edema (DME)\") \nmultipleImages = glob(data_dir + '/train/DME/**')\ni = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor im in multipleImages[:25]:\n    image = mpimg.imread(im)\n    image_resized = resize(image, (128, 128)) \n    plt.subplot(5, 5, i+1) #.set_title(l)\n    plt.imshow(gray2rgb(image_resized)); plt.axis('off')\n    i += 1\nplt.savefig('dme_eye.png', transparent= False, bbox_inches= 'tight', dpi= 400)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Drusen\")\nmultipleImages = glob(data_dir + '/train/DRUSEN/**')\ni = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor im in multipleImages[:25]:\n    image = mpimg.imread(im)\n    image_resized = resize(image, (128, 128)) \n    plt.subplot(5, 5, i+1) #.set_title(l)\n    plt.imshow(gray2rgb(image_resized)); plt.axis('off')\n    i += 1\nplt.savefig('drusen_eye.png', transparent= False, bbox_inches= 'tight', dpi= 400)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Keras Data Generators","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale= 1./255,\n    zoom_range= (0.73, 0.9),\n    horizontal_flip= True,\n    rotation_range= 10,\n    width_shift_range= 0.10,\n    fill_mode= 'constant',\n    height_shift_range= 0.10,   \n    brightness_range= (0.55, 0.9),\n)\n\nvalid_test_datagen = ImageDataGenerator(\n    rescale= 1./255, \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(  \n    train_data_dir,  \n    target_size= (img_width, img_height), \n    color_mode= 'rgb',\n    batch_size= batch_size,  \n    class_mode= 'categorical',\n    shuffle= True, \n    seed= 1337\n) \n\nvalid_generator = valid_test_datagen.flow_from_directory(\n    val_data_dir,\n    target_size= (img_width, img_height),\n    color_mode= 'rgb',\n    batch_size= batch_size,  \n    class_mode= 'categorical',\n    shuffle= True, \n    seed= 1337\n)\n\ntest_generator = valid_test_datagen.flow_from_directory(  \n    test_data_dir,  \n    target_size= (img_width, img_height), \n    color_mode= 'rgb',\n    batch_size= batch_size,        \n    class_mode= 'categorical',\n    shuffle= False, \n    \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = len(train_generator.class_indices)  \ntrain_labels = train_generator.classes \ntrain_labels = to_categorical(train_labels, num_classes=num_classes)\nvalid_labels = valid_generator.classes \nvalid_labels = to_categorical(valid_labels, num_classes=num_classes)\nnb_train_samples = len(train_generator.filenames)  \nnb_valid_samples = len(valid_generator.filenames)\nnb_test_samples = len(test_generator.filenames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Data Augmentation","metadata":{}},{"cell_type":"code","source":"img = load_img(\"/kaggle/input/medical-image-data/train/NORMAL/NORMAL-1014715-9.jpeg\")\ndata = img_to_array(img)\nsamples = expand_dims(data, 0)\nit = train_datagen.flow(samples, batch_size=1)\nplt.rcParams['figure.figsize'] = (8.0, 8.0)\n\nfor i in range(9):\n\tplt.subplot(330 + 1 + i)\n\tbatch = it.next()\n\timage = batch[0]\n\tplt.imshow(image)\n\nplt.savefig('augmented_image.png', transparent= False, bbox_inches= 'tight', dpi= 400)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model\n* VGG16 CNN architecture is used for calssification.\n* Pretrained on the 'ImageNet' dataset.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Detect and initialize the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# Instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nvgg16 = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(img_width, img_height, channels))\nvgg16.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = tf.keras.Sequential()\nfor layer in vgg16.layers:\n    model.add(layer)\n\nfor layer in model.layers:\n    layer.trainable= False\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(4, activation='softmax'))\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VGG16 Architecture","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nimport pydot\nplot_model(model,to_file='/kaggle/input/model-plot', show_shapes=True, show_layer_names=True)\nfrom IPython.display import Image\nImage('/kaggle/input/model-plot/model_plot.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline Model Training","metadata":{}},{"cell_type":"code","source":"model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a TPU-compatible ModelCheckpoint callback\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    'baseline_model.h5',\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='auto',\n    save_weights_only=False,\n    save_freq='epoch'\n)\n\n# Define other callbacks (EarlyStopping, CSVLogger, ReduceLROnPlateau)\nearlystop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=3,\n    verbose=1,\n    mode='auto'\n)\n\ncsvlogger = tf.keras.callbacks.CSVLogger(\n    filename=\"baseline_training_csv.log\",\n    separator=\",\",\n    append=False\n)\n\nreduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.1,\n    patience=3,\n    verbose=1,\n    mode='auto'\n)\n\n# Combine all callbacks\ncallbacks = [checkpoint, earlystop, csvlogger, reduceLR]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the training parameters\nepochs = 30\nsteps_per_epoch = nb_train_samples // batch_size\nvalidation_steps = nb_valid_samples // batch_size\n\n# Train the model on the TPU\nhistory = model.fit(\n    train_generator,\n    epochs=epochs,\n    steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps,\n    verbose=2,\n    callbacks=callbacks,\n    shuffle=True\n)\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(eval_loss, eval_accuracy) = model.evaluate(test_generator, batch_size= batch_size, verbose= 1)\nprint('Test Loss: ', eval_loss)\nprint('Test Accuracy: ', eval_accuracy)\n     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}